# StackMix and Blot Augmentations for Handwritten Text Recognition
paper [arxiv](https://arxiv.org/abs/2108.11667)  [paperswithcode](https://paperswithcode.com/paper/stackmix-and-blot-augmentations-for) [StackMix-OCR-github](https://github.com/ai-forever/StackMix-OCR)

Datasets Used [IAM](https://paperswithcode.com/dataset/iam) [HKR](https://paperswithcode.com/dataset/hkr) [HKR-Dataset](https://github.com/abdoelsayed2016/HKR_Dataset) [Digital-Peter](https://paperswithcode.com/dataset/digital-peter) [cyrillic-handwriting-dataset-kaggle](https://www.kaggle.com/datasets/constantinwerner/cyrillic-handwriting-dataset)

examples [AmalAkh/russian-handwritten-text-recognition](https://github.com/AmalAkh/russian-handwritten-text-recognition/tree/main)

В тексте рассматриваются различные методы и подходы к распознаванию рукописного текста (HTR) с использованием моделей глубокого обучения. В начале излагаются первые работы по проблемам распознавания рукописного текста, в которых использовалась комбинация скрытых марковских моделей и рекуррентных нейронных сетей (RNN) или алгоритмы на основе условных случайных полей. Однако было обнаружено, что эти подходы имеют свои недостатки, в частности, невозможность оптимизации сквозной функции потерь.

В 2006 году был представлен новый подход, известный как коннекционистская темпоральная классификация (CTC). Этот подход интерпретирует выходные данные сети как распределение вероятностей по всем возможным последовательностям меток, обусловленным заданной входной последовательностью. Это позволяет получить целевую функцию, которая непосредственно максимизирует вероятности правильных меток. Поскольку объективная функция дифференцируема, сеть может быть обучена стандартным методом обратного распространения во времени. В рамках этого подхода были введены потери CTC, которые нашли широкое признание среди исследователей и стали стандартом де-факто для распознавания рукописных работ.

Также были упомянуты MDLSTM-сети, использующие 2D-RNN. Эти сети могут работать с обеими осями входного изображения и состоят из нескольких слоев CNN и MDLSTM. Однако эти модели имеют ряд недостатков, таких как высокая вычислительная стоимость и нестабильность. Для решения этих проблем были предложены различные методы, такие как метод "упаковки примеров" из работы [10] и исключение рекуррентных слоев в CNN-LSTM-CTC для уменьшения количества параметров ieeexplore.ieee.org.

В качестве альтернативы подходу RCNN-CTC были также предложены модели Seq2seq. Эти модели используют кодер для извлечения признаков из входного сигнала и декодер с механизмом внимания для последовательной выдачи выходного сигнала. Обычные приемы могут существенно улучшить качество HTR-моделей arxiv.org.

Далее в тексте рассматривается новый метод дополнения данных, имитирующий зачеркнутый текст, известный как Handwritten Blots. Этот метод был разработан в ходе анализа набора данных Digital Peter и предполагает использование аугментации Cutout [12] для создания эффекта, похожего на перечеркнутые символы. Реализация этого алгоритма предполагает использование алгоритма построения кривой Безье для сглаживания перехода кривой между точками arxiv.org.

Наконец, в тексте описывается предложенная модель, состоящая из трех частей: модифицированной архитектуры нейронной сети Resnet, нового метода аугментации, имитирующего зачеркнутый текст, и метода значительного увеличения объема обучающих данных за счет генерации нового текста в стиле текущего набора данных. Результаты, полученные при использовании этой архитектуры без дополнительных модификаций, приведены в табл. 4, а влияние дополнения Blot на метрики качества также обсуждается arxiv.org.

| The text discusses various methods and approaches to handwritten text recognition (HTR) using deep learning models. It begins by outlining early works on handwritten recognition problems that used a combination of hidden Markov models and Recurrent Neural Networks (RNNs) or algorithms based on conditional random fields. However, these approaches were found to have limitations, particularly the inability to optimize an end-to-end loss function.

| In 2006, a new approach known as Connectionist Temporal Classification (CTC) was introduced. This approach interprets the network outputs as a probability distribution over all possible label sequences, conditioned on a given input sequence. This allows for the derivation of an objective function that directly maximizes the probabilities of the correct labelings. Since the objective function is differentiable, the network can be trained using standard backpropagation through time. The introduction of CTC loss was also part of this approach, which found wide acceptance among researchers and became the de-facto standard for handwritten recognition works arxiv.org.

| MDLSTM networks that use 2D-RNN were also mentioned. These networks can handle both axes of an input image and consist of several CNN and MDLSTM layers. However, these models have some disadvantages, such as high computational costs and instability. To address these issues, various methods were proposed, such as the "example-packing" method from work [10] and the elimination of recurrent layers in CNN-LSTM-CTC to decrease the number of parameters ieeexplore.ieee.org.

| Seq2seq models were also suggested as an alternative to the RCNN-CTC approach. These models use an encoder to extract features from the input and a decoder with an attention mechanism to emit the output sequentially. Common tricks can significantly improve the quality of HTR models arxiv.org.

| The text then discusses a new data augmentation method that simulates strikethrough text, known as Handwritten Blots. This method was developed during the analysis of the Digital Peter dataset and involves the use of the Cutout augmentation [12] to create an effect similar to crossed-out symbols. The implementation of this algorithm involves the use of the Bezier curve construction algorithm to smooth the curve transition between points arxiv.org.

| Finally, the text describes the proposed model, which comprises three parts: a modified Resnet neural network architecture, a new augmentation method that simulates strikethrough text, and a method for significantly increasing the amount of training data by generating new text in the style of the current dataset. The results achieved using this architecture without any additional modifications are shown in Table 4, and the effect of the Blot augmentation on quality metrics is also discussed arxiv.org.
